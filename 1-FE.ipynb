{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from category_encoders import TargetEncoder, CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80176, 12) (34365, 12)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "targets = train[\"label\"].values\n",
    "\n",
    "train.drop([\"Unnamed: 0\", \"label\"], inplace=True, axis=1)\n",
    "test.drop([\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"org\", \"tld\", \"mail_type\"]\n",
    "binary_features = [\"ccs\", \"bcced\", \"salutations\", \"designation\"]\n",
    "numerical_features = [\"images\", \"urls\", \"chars_in_subject\", \"chars_in_body\"]\n",
    "\n",
    "target = \"target\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the date feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsedate(s : str):\n",
    "    if s=='11-MAR-2018 20:40:58':\n",
    "        d = ' '.join(['11 Mar 2018', '20:40:58', '+0000'])\n",
    "    else:\n",
    "        s = s.replace('0580', '0530')\n",
    "        s = s.replace('-0000', '+0000')\n",
    "        tz = re.search('[+-]{1}[0-9]{4}|$', s).group()\n",
    "        if tz=='':\n",
    "            tz='+0000'\n",
    "        date = re.search('[0-9]{1,2}\\s+[A-Za-z]{3}\\s+[0-9]{2,4}|$', s).group()\n",
    "        time = re.search('[0-9]{2}:[0-9]{2}:[0-9]{2}|$', s).group()\n",
    "        d= ' '.join([date, time, tz])\n",
    "    try:\n",
    "        res = datetime.strptime(d, '%d %b %Y %H:%M:%S %z')\n",
    "    except Exception as e:\n",
    "        res = datetime.strptime(d, '%d %b %y %H:%M:%S %z')\n",
    "    return res\n",
    "\n",
    "train[\"date\"] = train[\"date\"].map(lambda d: parsedate(d))\n",
    "test[\"date\"] = test[\"date\"].map(lambda d: parsedate(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"year\"] = train[\"date\"].map(lambda d: d.year)\n",
    "test[\"year\"] = test[\"date\"].map(lambda d: d.year)\n",
    "\n",
    "train[\"month\"] = train[\"date\"].map(lambda d: d.month)\n",
    "test[\"month\"] = test[\"date\"].map(lambda d: d.month)\n",
    "\n",
    "train[\"weekday\"] = train[\"date\"].map(lambda d: d.weekday())\n",
    "test[\"weekday\"] = test[\"date\"].map(lambda d: d.weekday())\n",
    "\n",
    "#train[\"weekend\"] = train[\"weekday\"].map(lambda n: int(n > 5))\n",
    "#test[\"weekend\"] = train[\"weekday\"].map(lambda n: int(n > 5))\n",
    "\n",
    "train[\"hour\"] = train[\"date\"].map(lambda d: d.hour)\n",
    "test[\"hour\"] = test[\"date\"].map(lambda d: d.hour)\n",
    "\n",
    "train[\"minute\"] = train[\"date\"].map(lambda d: d.minute)\n",
    "test[\"minute\"] = test[\"date\"].map(lambda d: d.minute)\n",
    "\n",
    "train[\"second\"] = train[\"date\"].map(lambda d: d.second)\n",
    "test[\"second\"] = test[\"date\"].map(lambda d: d.second)\n",
    "\n",
    "train['timezone'] = train['date'].apply(lambda x: x.tzname())\n",
    "test['timezone'] = test['date'].apply(lambda x: x.tzname())\n",
    "\n",
    "categorical_features.append(\"timezone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_feature in categorical_features:\n",
    "    train[categorical_feature] = train[categorical_feature].fillna(\"missing\")\n",
    "    test[categorical_feature] = test[categorical_feature].fillna(\"missing\")\n",
    "\n",
    "    train[categorical_feature] = train[categorical_feature].map(lambda t: t.strip().lower() \n",
    "                                                                if type(t) != float \n",
    "                                                                else t)\n",
    "    \n",
    "    test[categorical_feature] = test[categorical_feature].map(lambda t: t.strip().lower() \n",
    "                                                              if type(t) != float \n",
    "                                                              else t) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding counts for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for categorical_feature in categorical_features:\n",
    "    \n",
    "    vc = train[categorical_feature].value_counts()\n",
    "    mean_count = vc.mean()\n",
    "    vc = vc.to_dict()\n",
    "    \n",
    "    train[f\"{categorical_feature}_count\"] = train[categorical_feature].map(vc)\n",
    "    test[f\"{categorical_feature}_count\"] = test[categorical_feature].map(lambda k: vc[k] if k in vc \n",
    "                                                                         else mean_count)\n",
    "                                                                         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"full_content_length\"] = train[\"chars_in_body\"] + train[\"chars_in_subject\"]\n",
    "test[\"full_content_length\"] = test[\"chars_in_body\"] + test[\"chars_in_subject\"]\n",
    "\n",
    "train[\"cc_bcc\"] = train[\"bcced\"] + train[\"ccs\"]\n",
    "test[\"cc_bcc\"] = test[\"bcced\"] + test[\"ccs\"]\n",
    "\n",
    "for f in [\"chars_in_subject\", \"full_content_length\"]:\n",
    "    train[f].fillna(train[f].median(), inplace=True)\n",
    "    test[f].fillna(train[f].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding  the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"target\"\n",
    "assert method in [\"label\", \"target\", \"onehot\", \"catboost\"]\n",
    "\n",
    "if method == \"label\":\n",
    "    for categorical_feature in categorical_features:\n",
    "        train[categorical_feature] = train[categorical_feature].fillna(\"missing\")\n",
    "        test[categorical_feature] = test[categorical_feature].fillna(\"missing\")\n",
    "        \n",
    "    for categorical_feature in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(train[categorical_feature].tolist() + test[categorical_feature].tolist())\n",
    "        train[categorical_feature] = le.transform(train[categorical_feature])\n",
    "        test[categorical_feature] = le.transform(test[categorical_feature])\n",
    "        \n",
    "elif method == \"target\":\n",
    "    target_encoder = TargetEncoder(cols=categorical_features)\n",
    "    train = target_encoder.fit_transform(train, targets)\n",
    "    test = target_encoder.transform(test)\n",
    "    \n",
    "elif method == \"catboost\":\n",
    "    catboost_encoder = CatBoostEncoder(cols=categorical_features)\n",
    "    train = catboost_encoder.fit_transform(train, targets)\n",
    "    test = catboost_encoder.transform(test)\n",
    "\n",
    "elif method == \"onehot\":\n",
    "    for categorical_feature in categorical_features:\n",
    "        train[categorical_feature] = train[categorical_feature].fillna(\"missing\")\n",
    "        test[categorical_feature] = test[categorical_feature].fillna(\"missing\")\n",
    "    \n",
    "    for categorical_feature in categorical_features:\n",
    "        \n",
    "        dummy = pd.get_dummies(pd.concat([train, test], axis=0)[categorical_feature], \n",
    "                               prefix=f\"{categorical_feature}__\")\n",
    "        dummy.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        dummy_train = dummy.loc[:len(train)-1]\n",
    "        dummy_test = dummy.loc[len(train):]\n",
    "        dummy_test.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        train = pd.concat([train, dummy_train], axis=1)\n",
    "        test = pd.concat([test, dummy_test], axis=1)\n",
    "        \n",
    "\n",
    "    binary_columns = [c for c in train.columns if \"__\" in c]\n",
    "    train.drop(categorical_features, inplace=True, axis=1)\n",
    "    test.drop(categorical_features, inplace=True, axis=1)\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=50)\n",
    "    svd.fit(train[binary_columns])\n",
    "    \n",
    "    print(\"explained ratio :\", svd.explained_variance_ratio_.sum())\n",
    "    \n",
    "    reduced_binary_train = svd.transform(train[binary_columns])\n",
    "    reduced_binary_test = svd.transform(test[binary_columns])\n",
    "    \n",
    "    train.drop(binary_columns, inplace=True, axis=1)\n",
    "    test.drop(binary_columns, inplace=True, axis=1)\n",
    "    \n",
    "    train = pd.concat([train, pd.DataFrame(reduced_binary_train)], axis=1)\n",
    "    test = pd.concat([test, pd.DataFrame(reduced_binary_test)], axis=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"label\"] = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(\"date\", inplace=True, axis=1)\n",
    "test.drop(\"date\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80176, 21) (34365, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(f\"../data/processed/{method}/train.csv\", index=False)\n",
    "test.to_csv(f\"../data/processed/{method}/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
