# Machine-Learning-Kaggle-Classification-Emails

Here are the different steps :

- Data processing
- Feature engineering
- Running a baseline model
- Finetuning a model
- Fitting the best model
- Predict

---

Some papers and blog posts that Hestia and I found on different techniques : 

Models:

- Random forest: [https://www.analyticsvidhya.com/blog/2020/03/beginners-guide-random-forest-hyperparameter-tuning/](https://www.analyticsvidhya.com/blog/2020/03/beginners-guide-random-forest-hyperparameter-tuning/)
- XGboost: [https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e](https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e)
- lightgbm and catboost: [https://mlexplained.com/2018/01/05/lightgbm-and-xgboost-explained/](https://mlexplained.com/2018/01/05/lightgbm-and-xgboost-explained/)
- the impact of lightgbm parameters: [https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)

VERY IMPORTANT Target encoding:

- [https://maxhalford.github.io/blog/target-encoding/](https://maxhalford.github.io/blog/target-encoding/)
- [https://brendanhasz.github.io/2019/03/04/target-encoding#target-encoding](https://brendanhasz.github.io/2019/03/04/target-encoding#target-encoding)
- [https://contrib.scikit-learn.org/category_encoders/targetencoder.html](https://contrib.scikit-learn.org/category_encoders/targetencoder.html)
